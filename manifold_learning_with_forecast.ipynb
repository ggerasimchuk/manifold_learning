{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production Behavior Manifold & Forecast\n",
    "\n",
    "Обновлённый ноутбук объединяет основные шаги пайплайна PBM в единое рабочее место:\n",
    "1. Загрузка и очистка сырых ежемесячных отчётов.\n",
    "2. Предобработка профилей (Step 1) и сохранение результатов.\n",
    "3. Построение дескрипторов, manifold-embedding и кластеризация.\n",
    "4. Генерация отчётов по сегментации.\n",
    "5. Построение прогнозов по префиксу (20 → 100).\n",
    "\n",
    "Ниже каждая секция изолирована функциями и настройками, что упрощает повторный запуск и адаптацию под другие проекты.\n"
   ],
   "id": "a7ded500dc7ef217"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Импорт, конфигурация и утилиты\n"
   ],
   "id": "6f7b91338b73191d"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T06:55:08.976316Z",
     "start_time": "2025-09-16T06:55:08.973957Z"
    }
   },
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"SCIPY_ARRAY_API\"] = \"1\"\n",
    "\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.width = 120\n"
   ],
   "id": "bb22864aed3e8493",
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T06:55:08.990737Z",
     "start_time": "2025-09-16T06:55:08.988492Z"
    }
   },
   "source": [
    "# Базовые пути и параметры выполнения\n",
    "DATA_DIR = Path(\"data/wells\")\n",
    "FORECAST_EXPORT_DIR = Path(\"reports/forecast_exports\")\n",
    "PBM_REPORT_DIR = Path(\"reports/pbm_report_exports\")\n",
    "\n",
    "# Ограничители для быстрых прогонов (None -> использовать всё)\n",
    "MAX_CSV_FILES: Optional[int] = 1000   # например, 5 чтобы взять только первые файлы\n",
    "SAMPLE_WELLS: Optional[int] = 1000    # например, 500 чтобы ограничить число скважин\n",
    "\n",
    "# Параметры шагов\n",
    "RUN_MANIFOLD = True\n",
    "RUN_CLUSTERING = True\n",
    "RUN_PBM_REPORT = True  # отчёт требует matplotlib/hdbscan и может быть тяжёлым\n",
    "RUN_FORECAST = True\n",
    "\n",
    "FORECAST_PREFIX = 20\n",
    "RANDOM_SEED = 59\n",
    "\n",
    "pipeline_state: Dict[str, Any] = {}\n"
   ],
   "id": "5adf0b189a0085da",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T06:55:09.003854Z",
     "start_time": "2025-09-16T06:55:08.999634Z"
    }
   },
   "source": [
    "def discover_csv_files(data_dir: Path, limit: Optional[int] = None) -> list[Path]:\n",
    "    \"\"\"Поиск CSV с исходными данными.\"\"\"\n",
    "    if not data_dir.exists():\n",
    "        raise FileNotFoundError(f\"Каталог {data_dir} не найден.\")\n",
    "    csv_files = sorted(data_dir.glob(\"*.csv\"))\n",
    "    if limit is not None:\n",
    "        csv_files = csv_files[:limit]\n",
    "    if not csv_files:\n",
    "        raise FileNotFoundError(f\"В каталоге {data_dir} нет csv-файлов.\")\n",
    "    return csv_files\n",
    "\n",
    "RENAME_MAP = {\n",
    "    \"BBLS_OIL_COND\": \"oil\",\n",
    "    \"MCF_GAS\": \"gas\",\n",
    "    \"BBLS_WTR\": \"water\",\n",
    "    \"API_WellNo\": \"well_name\",\n",
    "    \"RptDate\": \"date\",\n",
    "    \"DAYS_PROD\": \"days_prod\",\n",
    "}\n",
    "\n",
    "def load_raw_well_data(data_dir: Path, limit_files: Optional[int] = None) -> pd.DataFrame:\n",
    "    csv_files = discover_csv_files(data_dir, limit_files)\n",
    "    frames = [pd.read_csv(path) for path in csv_files]\n",
    "    df = pd.concat(frames, ignore_index=True)\n",
    "    print(f\"Считано файлов: {len(csv_files)} — строк: {len(df):,}\")\n",
    "    return df\n",
    "\n",
    "def clean_well_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.rename(columns=RENAME_MAP)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    drop_cols = [c for c in (\"Lease_Unit\", \"Formation\") if c in df.columns]\n",
    "    if drop_cols:\n",
    "        df = df.drop(columns=drop_cols)\n",
    "    df = df[(df[\"oil\"] >= 0) & (df[\"gas\"] >= 0) & (df[\"water\"] >= 0)].copy()\n",
    "    df = df.sort_values(by=[\"well_name\", \"date\"]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def subset_wells(df: pd.DataFrame, n_wells: Optional[int] = None) -> pd.DataFrame:\n",
    "    if n_wells is None:\n",
    "        return df\n",
    "    wells = (\n",
    "        df[\"well_name\"]\n",
    "        .dropna()\n",
    "        .drop_duplicates()\n",
    "        .sort_values()\n",
    "        .head(n_wells)\n",
    "    )\n",
    "    return df[df[\"well_name\"].isin(wells)].copy()\n",
    "\n",
    "def prepare_dataset(data_dir: Path, limit_files: Optional[int] = None, sample_wells: Optional[int] = None) -> pd.DataFrame:\n",
    "    raw = load_raw_well_data(data_dir, limit_files)\n",
    "    cleaned = clean_well_data(raw)\n",
    "    subset = subset_wells(cleaned, sample_wells)\n",
    "    print(f\"Итоговый датафрейм: {subset.shape[0]:,} строк, {subset['well_name'].nunique()} скважин\")\n",
    "    return subset\n"
   ],
   "id": "6cdedb6391168469",
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T06:55:09.780098Z",
     "start_time": "2025-09-16T06:55:09.011036Z"
    }
   },
   "source": [
    "try:\n",
    "    df = prepare_dataset(DATA_DIR, MAX_CSV_FILES, SAMPLE_WELLS)\n",
    "except FileNotFoundError as exc:\n",
    "    print(f\"⚠️ {exc}\")\n",
    "    df = None\n",
    "else:\n",
    "    pipeline_state[\"dataframe\"] = df\n",
    "    display(df.head())\n"
   ],
   "id": "e74cb6ee288346f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Считано файлов: 1000 — строк: 266,616\n",
      "Итоговый датафрейм: 266,578 строк, 945 скважин\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "            well_name       date  oil  gas  water  days_prod\n",
       "0  25-003-05057-00-00 1986-01-31  149    0   1788       31.0\n",
       "1  25-003-05057-00-00 1986-03-31  210    0   2520       31.0\n",
       "2  25-003-05057-00-00 1986-04-30  252    0   3024       31.0\n",
       "3  25-003-05057-00-00 1986-05-31  264    0   3172       31.0\n",
       "4  25-003-05057-00-00 1986-06-30  192    0   2296       31.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>well_name</th>\n",
       "      <th>date</th>\n",
       "      <th>oil</th>\n",
       "      <th>gas</th>\n",
       "      <th>water</th>\n",
       "      <th>days_prod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25-003-05057-00-00</td>\n",
       "      <td>1986-01-31</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>1788</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25-003-05057-00-00</td>\n",
       "      <td>1986-03-31</td>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "      <td>2520</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25-003-05057-00-00</td>\n",
       "      <td>1986-04-30</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>3024</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25-003-05057-00-00</td>\n",
       "      <td>1986-05-31</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>3172</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25-003-05057-00-00</td>\n",
       "      <td>1986-06-30</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>2296</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Предобработка профилей (PBM Step 1)\n"
   ],
   "id": "71d57e7c5eaebde"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T06:55:25.317616Z",
     "start_time": "2025-09-16T06:55:09.787614Z"
    }
   },
   "source": [
    "from tools.preprocessing import PreprocConfig, preprocess_profiles\n",
    "\n",
    "def run_preprocessing(df: pd.DataFrame, cfg: Optional[PreprocConfig] = None) -> Dict[str, Any]:\n",
    "    if df is None:\n",
    "        raise ValueError(\"Нет исходных данных — убедитесь, что предыдущая ячейка выполнена успешно.\")\n",
    "    cfg = cfg or PreprocConfig()\n",
    "    print(f\"Запуск preprocess_profiles для {df['well_name'].nunique()} скважин (T={cfg.T})\")\n",
    "    out = preprocess_profiles(df, cfg)\n",
    "    print(\"panel_long shape:\", out[\"panel_long\"].shape)\n",
    "    print(\"tensor shape:\", out[\"X\"].shape)\n",
    "    display(out[\"panel_long\"].head(12))\n",
    "    out[\"config\"] = dict(out.get(\"config\", {}))\n",
    "    return out\n",
    "\n",
    "preproc_cfg = PreprocConfig()\n",
    "preproc_out = run_preprocessing(df, preproc_cfg) if df is not None else None\n",
    "pipeline_state[\"preprocessing\"] = preproc_out\n",
    "out = preproc_out  # совместимость со старыми скриптами\n"
   ],
   "id": "973d85a466aef37f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Запуск preprocess_profiles для 945 скважин (T=70)\n",
      "Preprocess complete.\n",
      "  В итог попало скважин: 531\n",
      "  Отброшено (по причинам):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "              reason  count\n",
       "0  no_start_detected    399\n",
       "1     too_short(<12)     15"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reason</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no_start_detected</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>too_short(&lt;12)</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "panel_long shape: (35446, 21)\n",
      "tensor shape: (531, 70, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "             well_name       date  oil_sum  water_sum  gas_sum  days_sum  valid_days  days_eff     r_oil     r_water  \\\n",
       "0   25-003-05057-00-00 1986-01-01    149.0     1788.0      0.0      31.0           1      31.0  4.806452   57.677419   \n",
       "1   25-003-05057-00-00 1986-03-01    210.0     2520.0      0.0      31.0           1      31.0  6.575484   81.290323   \n",
       "2   25-003-05057-00-00 1986-04-01    252.0     3024.0      0.0      31.0           1      31.0  6.575484   97.548387   \n",
       "3   25-003-05057-00-00 1986-05-01    264.0     3172.0      0.0      31.0           1      31.0  6.575484  102.322581   \n",
       "4   25-003-05057-00-00 1986-06-01    192.0     2296.0      0.0      31.0           1      31.0  6.193548   74.064516   \n",
       "5   25-003-05057-00-00 1986-07-01    206.0     2464.0      0.0      31.0           1      31.0  6.575484   79.483871   \n",
       "6   25-003-05057-00-00 1986-08-01    208.0     2488.0      0.0      31.0           1      31.0  6.575484   80.258065   \n",
       "7   25-003-05057-00-00 1986-09-01    203.0     2444.0      0.0      31.0           1      31.0  6.548387   78.838710   \n",
       "8   25-003-05057-00-00 1986-10-01    154.0     1856.0      0.0      31.0           1      31.0  4.967742   59.870968   \n",
       "9   25-003-05057-00-00 1986-11-01    148.0     1776.0      0.0      31.0           1      31.0  4.774194   57.290323   \n",
       "10  25-003-05057-00-00 1986-12-01    150.0     1792.0      0.0      31.0           1      31.0  4.838710   57.806452   \n",
       "11  25-003-05057-00-00 1987-01-01    151.0     1804.0      0.0      31.0           1      31.0  4.870968   58.193548   \n",
       "\n",
       "    r_gas   r_oil_s  r_water_s  r_gas_s        wc  gor  r_oil_norm  r_water_norm  r_gas_norm  dr_oil_norm   t  \n",
       "0     0.0  4.975889  55.358525      0.0  0.917528  0.0    0.736094      8.189310         0.0          NaN   0  \n",
       "1     0.0  6.175152  85.430415      0.0  0.932590  0.0    0.913504     12.637911         0.0     0.177410   1  \n",
       "2     0.0  6.759853  99.041475      0.0  0.936108  0.0    1.000000     14.651425         0.0     0.086496   2  \n",
       "3     0.0  6.444535  94.757604      0.0  0.936320  0.0    0.953354     14.017703         0.0    -0.046646   3  \n",
       "4     0.0  6.389972  83.067281      0.0  0.928570  0.0    0.945283     12.288327         0.0    -0.008072   4  \n",
       "5     0.0  6.446857  75.988940      0.0  0.921795  0.0    0.953698     11.241213         0.0     0.008415   5  \n",
       "6     0.0  6.736737  81.784332      0.0  0.923897  0.0    0.996581     12.098538         0.0     0.042883   6  \n",
       "7     0.0  6.165493  74.613825      0.0  0.923675  0.0    0.912075     11.037789         0.0    -0.084505   7  \n",
       "8     0.0  5.316571  63.918894      0.0  0.923210  0.0    0.786492      9.455664         0.0    -0.125583   8  \n",
       "9     0.0  4.702304  56.427650      0.0  0.923077  0.0    0.695622      8.347468         0.0    -0.090870   9  \n",
       "10    0.0  4.855300  58.005530      0.0  0.922761  0.0    0.718255      8.580887         0.0     0.022633  10  \n",
       "11    0.0  4.699539  56.280184      0.0  0.922933  0.0    0.695213      8.325653         0.0    -0.023042  11  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>well_name</th>\n",
       "      <th>date</th>\n",
       "      <th>oil_sum</th>\n",
       "      <th>water_sum</th>\n",
       "      <th>gas_sum</th>\n",
       "      <th>days_sum</th>\n",
       "      <th>valid_days</th>\n",
       "      <th>days_eff</th>\n",
       "      <th>r_oil</th>\n",
       "      <th>r_water</th>\n",
       "      <th>r_gas</th>\n",
       "      <th>r_oil_s</th>\n",
       "      <th>r_water_s</th>\n",
       "      <th>r_gas_s</th>\n",
       "      <th>wc</th>\n",
       "      <th>gor</th>\n",
       "      <th>r_oil_norm</th>\n",
       "      <th>r_water_norm</th>\n",
       "      <th>r_gas_norm</th>\n",
       "      <th>dr_oil_norm</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25-003-05057-00-00</td>\n",
       "      <td>1986-01-01</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1788.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4.806452</td>\n",
       "      <td>57.677419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.975889</td>\n",
       "      <td>55.358525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.917528</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.736094</td>\n",
       "      <td>8.189310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25-003-05057-00-00</td>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>210.0</td>\n",
       "      <td>2520.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.575484</td>\n",
       "      <td>81.290323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.175152</td>\n",
       "      <td>85.430415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.932590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.913504</td>\n",
       "      <td>12.637911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177410</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25-003-05057-00-00</td>\n",
       "      <td>1986-04-01</td>\n",
       "      <td>252.0</td>\n",
       "      <td>3024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.575484</td>\n",
       "      <td>97.548387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.759853</td>\n",
       "      <td>99.041475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.936108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.651425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086496</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25-003-05057-00-00</td>\n",
       "      <td>1986-05-01</td>\n",
       "      <td>264.0</td>\n",
       "      <td>3172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.575484</td>\n",
       "      <td>102.322581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.444535</td>\n",
       "      <td>94.757604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.936320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.953354</td>\n",
       "      <td>14.017703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.046646</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25-003-05057-00-00</td>\n",
       "      <td>1986-06-01</td>\n",
       "      <td>192.0</td>\n",
       "      <td>2296.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.193548</td>\n",
       "      <td>74.064516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.389972</td>\n",
       "      <td>83.067281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.928570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.945283</td>\n",
       "      <td>12.288327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.008072</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25-003-05057-00-00</td>\n",
       "      <td>1986-07-01</td>\n",
       "      <td>206.0</td>\n",
       "      <td>2464.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.575484</td>\n",
       "      <td>79.483871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.446857</td>\n",
       "      <td>75.988940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.921795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.953698</td>\n",
       "      <td>11.241213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008415</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25-003-05057-00-00</td>\n",
       "      <td>1986-08-01</td>\n",
       "      <td>208.0</td>\n",
       "      <td>2488.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.575484</td>\n",
       "      <td>80.258065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.736737</td>\n",
       "      <td>81.784332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.923897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996581</td>\n",
       "      <td>12.098538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042883</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25-003-05057-00-00</td>\n",
       "      <td>1986-09-01</td>\n",
       "      <td>203.0</td>\n",
       "      <td>2444.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.548387</td>\n",
       "      <td>78.838710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.165493</td>\n",
       "      <td>74.613825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.923675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.912075</td>\n",
       "      <td>11.037789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.084505</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25-003-05057-00-00</td>\n",
       "      <td>1986-10-01</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1856.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4.967742</td>\n",
       "      <td>59.870968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.316571</td>\n",
       "      <td>63.918894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.923210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.786492</td>\n",
       "      <td>9.455664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.125583</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25-003-05057-00-00</td>\n",
       "      <td>1986-11-01</td>\n",
       "      <td>148.0</td>\n",
       "      <td>1776.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4.774194</td>\n",
       "      <td>57.290323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.702304</td>\n",
       "      <td>56.427650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.695622</td>\n",
       "      <td>8.347468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.090870</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25-003-05057-00-00</td>\n",
       "      <td>1986-12-01</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1792.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4.838710</td>\n",
       "      <td>57.806452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.855300</td>\n",
       "      <td>58.005530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.922761</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.718255</td>\n",
       "      <td>8.580887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022633</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>25-003-05057-00-00</td>\n",
       "      <td>1987-01-01</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1804.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4.870968</td>\n",
       "      <td>58.193548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.699539</td>\n",
       "      <td>56.280184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.922933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.695213</td>\n",
       "      <td>8.325653</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.023042</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2–3. Компактные признаки и manifold\n"
   ],
   "id": "48151f649c7c9db"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T06:58:18.690077Z",
     "start_time": "2025-09-16T06:55:25.333257Z"
    }
   },
   "source": [
    "try:\n",
    "    from tools.feature import compute_side_features, scale_features\n",
    "    from tools.manifold import ManifoldConfig, embed_umap_euclid, embed_umap_fastdtw\n",
    "    MANIFOLD_IMPORT_ERROR = None\n",
    "except Exception as exc:\n",
    "    MANIFOLD_IMPORT_ERROR = exc\n",
    "\n",
    "def run_manifold(out_dict: Dict[str, Any], cfg: Optional[ManifoldConfig] = None, sample_size: Optional[int] = None) -> Dict[str, Any]:\n",
    "    if out_dict is None:\n",
    "        raise ValueError(\"Нет результатов предобработки.\")\n",
    "    if MANIFOLD_IMPORT_ERROR is not None:\n",
    "        raise RuntimeError(f\"Не удалось импортировать инструменты manifold: {MANIFOLD_IMPORT_ERROR}\")\n",
    "    cfg = cfg or ManifoldConfig()\n",
    "    panel_long = out_dict[\"panel_long\"]\n",
    "    X = out_dict[\"X\"]\n",
    "    wells = out_dict[\"wells_used\"]\n",
    "    tensor_channels = out_dict[\"tensor_channels\"]\n",
    "    T = int(out_dict.get(\"config\", {}).get(\"T\", X.shape[1]))\n",
    "\n",
    "    feats = compute_side_features(panel_long, T=T)\n",
    "    feats_scaled, scaler = scale_features(feats)\n",
    "    print(\"Side features shape:\", feats_scaled.shape)\n",
    "\n",
    "    Z_euclid, umap_e = embed_umap_euclid(\n",
    "        X,\n",
    "        tensor_channels=tensor_channels,\n",
    "        channels=cfg.channels,\n",
    "        n_neighbors=cfg.n_neighbors,\n",
    "        min_dist=cfg.min_dist,\n",
    "        n_components=cfg.n_components,\n",
    "        random_state=cfg.random_state,\n",
    "    )\n",
    "    print(\"UMAP (euclid) shape:\", Z_euclid.shape)\n",
    "\n",
    "    Z_dtw, sub_idx, dist_matrix, info = embed_umap_fastdtw(\n",
    "        X,\n",
    "        tensor_channels=tensor_channels,\n",
    "        channels=cfg.channels,\n",
    "        cfg=cfg,\n",
    "        sample_size=sample_size,\n",
    "    )\n",
    "    wells_sub = np.array(wells)[sub_idx]\n",
    "    embedding_df = pd.DataFrame({\n",
    "        \"well_name\": wells_sub,\n",
    "        \"x\": Z_dtw[:, 0],\n",
    "        \"y\": Z_dtw[:, 1],\n",
    "    })\n",
    "    display(embedding_df.head())\n",
    "    return {\n",
    "        \"cfg\": cfg,\n",
    "        \"features\": feats,\n",
    "        \"features_scaled\": feats_scaled,\n",
    "        \"scaler\": scaler,\n",
    "        \"Z_euclid\": Z_euclid,\n",
    "        \"Z_dtw\": Z_dtw,\n",
    "        \"sub_idx\": sub_idx,\n",
    "        \"dist_matrix\": dist_matrix,\n",
    "        \"info\": info,\n",
    "        \"embedding_df\": embedding_df,\n",
    "    }\n",
    "\n",
    "manifold_cfg = None\n",
    "manifold_out = None\n",
    "if RUN_MANIFOLD and preproc_out is not None:\n",
    "    manifold_cfg = ManifoldConfig(channels=(\"r_oil_norm\", \"wc\"), random_state=RANDOM_SEED)\n",
    "    manifold_out = run_manifold(preproc_out, manifold_cfg)\n",
    "pipeline_state[\"manifold\"] = manifold_out\n"
   ],
   "id": "19f10835f1e16b18",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Side features shape: (531, 16)\n",
      "UMAP (euclid) shape: (531, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recompute DTW for 15098 pairs (radius=6): 100%|██████████| 15098/15098 [02:50<00:00, 88.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "            well_name         x         y\n",
       "0  25-003-05057-00-00 -6.650459  1.323130\n",
       "1  25-003-05068-00-00 -6.725709  1.414207\n",
       "2  25-003-21142-00-00 -0.743979 -0.276046\n",
       "3  25-003-21143-00-00 -0.688707 -0.308407\n",
       "4  25-005-05034-00-00 -7.348205  0.515519"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>well_name</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25-003-05057-00-00</td>\n",
       "      <td>-6.650459</td>\n",
       "      <td>1.323130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25-003-05068-00-00</td>\n",
       "      <td>-6.725709</td>\n",
       "      <td>1.414207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25-003-21142-00-00</td>\n",
       "      <td>-0.743979</td>\n",
       "      <td>-0.276046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25-003-21143-00-00</td>\n",
       "      <td>-0.688707</td>\n",
       "      <td>-0.308407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25-005-05034-00-00</td>\n",
       "      <td>-7.348205</td>\n",
       "      <td>0.515519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Кластеризация и поиск аномалий\n"
   ],
   "id": "99252f9e6c0dae14"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T06:58:36.441318Z",
     "start_time": "2025-09-16T06:58:18.696738Z"
    }
   },
   "source": [
    "try:\n",
    "    from tools.clustering import (\n",
    "        ClusterConfig,\n",
    "        assign_anomaly_scores,\n",
    "        build_cluster_prototypes,\n",
    "        cluster_hdbscan,\n",
    "        summarize_clusters,\n",
    "    )\n",
    "    CLUSTER_IMPORT_ERROR = None\n",
    "except Exception as exc:\n",
    "    CLUSTER_IMPORT_ERROR = exc\n",
    "\n",
    "def run_clustering(out_dict: Dict[str, Any], manifold_dict: Dict[str, Any], cfg: Optional[ClusterConfig] = None) -> Optional[Dict[str, Any]]:\n",
    "    if out_dict is None or manifold_dict is None:\n",
    "        print(\"Кластеризация пропущена — нет данных manifold.\")\n",
    "        return None\n",
    "    if CLUSTER_IMPORT_ERROR is not None:\n",
    "        raise RuntimeError(f\"Не удалось импортировать инструменты кластеризации: {CLUSTER_IMPORT_ERROR}\")\n",
    "    cfg = cfg or ClusterConfig(min_cluster_size=45, min_samples=12)\n",
    "    embedding = manifold_dict.get(\"Z_dtw\")\n",
    "    sub_idx = manifold_dict.get(\"sub_idx\")\n",
    "    if embedding is None or sub_idx is None:\n",
    "        embedding = manifold_dict[\"Z_euclid\"]\n",
    "        sub_idx = np.arange(embedding.shape[0])\n",
    "    wells_sub = np.array(out_dict[\"wells_used\"])[sub_idx]\n",
    "    res = cluster_hdbscan(embedding, wells_sub.tolist(), cfg)\n",
    "    df_map = res[\"df_map\"]\n",
    "    df_map = assign_anomaly_scores(df_map, embedding, res[\"labels\"], lof_k=35)\n",
    "    summary = summarize_clusters(df_map)\n",
    "    display(summary)\n",
    "    prototypes = build_cluster_prototypes(\n",
    "        out_dict[\"panel_long\"],\n",
    "        df_map,\n",
    "        channels=(\"r_oil_s\", \"wc\", \"gor\", \"r_oil_norm\"),\n",
    "        T=int(out_dict[\"config\"][\"T\"]),\n",
    "        method=\"auto\",\n",
    "    )\n",
    "    print(f\"Silhouette={res['silhouette']:.3f}, DBCV={res['dbcv']:.3f}\")\n",
    "    return {\n",
    "        \"cfg\": cfg,\n",
    "        \"result\": res,\n",
    "        \"df_map\": df_map,\n",
    "        \"summary\": summary,\n",
    "        \"prototypes\": prototypes,\n",
    "    }\n",
    "\n",
    "cluster_cfg = None\n",
    "cluster_out = None\n",
    "if RUN_CLUSTERING and manifold_out is not None:\n",
    "    cluster_cfg = ClusterConfig(min_cluster_size=45, min_samples=12)\n",
    "    cluster_out = run_clustering(preproc_out, manifold_out, cluster_cfg)\n",
    "pipeline_state[\"clustering\"] = cluster_out\n"
   ],
   "id": "788058ea6950fccf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   cluster  size     share  prob_median\n",
       "0        0   204  0.384181     0.789915\n",
       "1        1   327  0.615819     1.000000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>size</th>\n",
       "      <th>share</th>\n",
       "      <th>prob_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>204</td>\n",
       "      <td>0.384181</td>\n",
       "      <td>0.789915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>327</td>\n",
       "      <td>0.615819</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette=0.717, DBCV=nan\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Экспорт отчёта PBM\n"
   ],
   "id": "c60090bdc189aa89"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T06:58:37.234738Z",
     "start_time": "2025-09-16T06:58:36.449983Z"
    }
   },
   "source": [
    "try:\n",
    "    from tools.make_reports import (\n",
    "        build_html_report,\n",
    "        export_csv_summaries,\n",
    "        save_cluster_distribution_plot,\n",
    "        save_cluster_prototype_plots,\n",
    "        save_pbm_map,\n",
    "    )\n",
    "    REPORT_IMPORT_ERROR = None\n",
    "except Exception as exc:\n",
    "    REPORT_IMPORT_ERROR = exc\n",
    "\n",
    "def build_pbm_report(preproc_dict: Dict[str, Any], manifold_dict: Dict[str, Any], cluster_dict: Dict[str, Any], out_dir: Path) -> Dict[str, Any]:\n",
    "    if cluster_dict is None:\n",
    "        print(\"Отчёт пропущен — кластеризация не выполнена.\")\n",
    "        return {}\n",
    "    if REPORT_IMPORT_ERROR is not None:\n",
    "        raise RuntimeError(f\"Не удалось импортировать генераторы отчётов: {REPORT_IMPORT_ERROR}\")\n",
    "    out_dir = Path(out_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    embedding = manifold_dict.get(\"Z_dtw\")\n",
    "    if embedding is None:\n",
    "        embedding = manifold_dict[\"Z_euclid\"]\n",
    "    df_map = cluster_dict[\"df_map\"]\n",
    "    map_png = save_pbm_map(embedding, df_map, str(out_dir))\n",
    "    sizes_png = save_cluster_distribution_plot(df_map, str(out_dir))\n",
    "    T = int(preproc_dict[\"config\"][\"T\"])\n",
    "    proto_pngs = save_cluster_prototype_plots(\n",
    "        preproc_dict[\"panel_long\"],\n",
    "        df_map,\n",
    "        cluster_dict[\"prototypes\"],\n",
    "        channels=(\"r_oil_s\", \"wc\", \"gor\", \"r_oil_norm\"),\n",
    "        T=T,\n",
    "        out_dir=str(out_dir),\n",
    "    )\n",
    "    summary = cluster_dict[\"summary\"]\n",
    "    csv_paths = export_csv_summaries(df_map, summary, str(out_dir), top_anoms=50)\n",
    "    report_path = build_html_report(\n",
    "        str(out_dir),\n",
    "        map_png,\n",
    "        sizes_png,\n",
    "        proto_pngs,\n",
    "        df_map,\n",
    "        summary,\n",
    "        title=\"PBM Report\",\n",
    "    )\n",
    "    print(\"Отчёт сохранён:\", report_path)\n",
    "    return {\n",
    "        \"out_dir\": out_dir,\n",
    "        \"map_png\": map_png,\n",
    "        \"sizes_png\": sizes_png,\n",
    "        \"proto_pngs\": proto_pngs,\n",
    "        \"csv_paths\": csv_paths,\n",
    "        \"report_path\": report_path,\n",
    "    }\n",
    "\n",
    "pbm_report = None\n",
    "if RUN_PBM_REPORT and cluster_out is not None:\n",
    "    pbm_report = build_pbm_report(preproc_out, manifold_out, cluster_out, PBM_REPORT_DIR)\n",
    "pipeline_state[\"pbm_report\"] = pbm_report\n"
   ],
   "id": "f89b3556c4ea1270",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отчёт сохранён: reports/pbm_report_exports/PBM_report.html\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Прогноз профиля (20 → 100)",
   "id": "69953d34698259ef"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T06:58:39.638304Z",
     "start_time": "2025-09-16T06:58:37.243417Z"
    }
   },
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from tools.forecast import (\n",
    "    build_prefix_scaled_channel,\n",
    "    evaluate_forecasts,\n",
    "    knn_forecast,\n",
    "    make_matrices,\n",
    "    multioutput_forecast,\n",
    ")\n",
    "\n",
    "def run_forecast_pipeline(out_dict: Dict[str, Any], T_pref: int, output_dir: Path, rng_seed: int = 59) -> Dict[str, Any]:\n",
    "    if out_dict is None:\n",
    "        raise ValueError(\"Нет результатов предобработки.\")\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    panel_long = out_dict[\"panel_long\"].copy()\n",
    "    wells_used = out_dict[\"wells_used\"]\n",
    "    T = int(out_dict[\"config\"][\"T\"])\n",
    "\n",
    "    panel_long = build_prefix_scaled_channel(\n",
    "        panel_long,\n",
    "        wells_used,\n",
    "        T=T,\n",
    "        T_pref=T_pref,\n",
    "        q=0.90,\n",
    "        rate_col=\"r_oil_s\",\n",
    "        out_col=\"r_oil_pref_norm\",\n",
    "    )\n",
    "\n",
    "    X_pref, Y_suffix_true, Y_full = make_matrices(\n",
    "        panel_long,\n",
    "        wells_used,\n",
    "        T=T,\n",
    "        T_pref=T_pref,\n",
    "        channel=\"r_oil_pref_norm\",\n",
    "        target_col=\"r_oil_s\",\n",
    "    )\n",
    "\n",
    "    Y_pred_knn, knn_info = knn_forecast(X_pref, Y_full, T_pref=T_pref, K=15)\n",
    "    Y_pred_lr, lr_info = multioutput_forecast(panel_long, wells_used, T=T, T_pref=T_pref, Y_full=Y_full, random_state=43)\n",
    "\n",
    "    metrics_knn = evaluate_forecasts(Y_suffix_true, Y_pred_knn)\n",
    "    metrics_lr = evaluate_forecasts(Y_suffix_true, Y_pred_lr)\n",
    "\n",
    "    metrics_df = pd.DataFrame([\n",
    "        {\"model\": \"knn\", **metrics_knn},\n",
    "        {\"model\": \"elasticnet\", **metrics_lr},\n",
    "    ])\n",
    "    metrics_path = output_dir / \"metrics.csv\"\n",
    "    metrics_df.to_csv(metrics_path, index=False)\n",
    "\n",
    "    np.save(output_dir / \"Y_suffix_true.npy\", Y_suffix_true)\n",
    "    np.save(output_dir / \"Y_pred_knn.npy\", Y_pred_knn)\n",
    "    np.save(output_dir / \"Y_pred_enet.npy\", Y_pred_lr)\n",
    "\n",
    "    suffix_cols = [f\"m{t}\" for t in range(T_pref + 1, T + 1)]\n",
    "\n",
    "    def save_suffix_csv(arr: np.ndarray, name: str) -> Path:\n",
    "        df_pred = pd.DataFrame(arr, columns=suffix_cols)\n",
    "        df_pred.insert(0, \"well_name\", wells_used)\n",
    "        path = output_dir / f\"pred_{name}.csv\"\n",
    "        df_pred.to_csv(path, index=False)\n",
    "        return path\n",
    "\n",
    "    suffix_paths = {\n",
    "        \"knn\": save_suffix_csv(Y_pred_knn, \"knn\"),\n",
    "        \"elasticnet\": save_suffix_csv(Y_pred_lr, \"elasticnet\"),\n",
    "    }\n",
    "\n",
    "    full_cols = [f\"m{t+1}\" for t in range(T)]\n",
    "\n",
    "    def save_full_csv(arr: np.ndarray, name: str) -> Path:\n",
    "        df_pred = pd.DataFrame(arr, columns=full_cols)\n",
    "        df_pred.insert(0, \"well_name\", wells_used)\n",
    "        path = output_dir / f\"pred_full_{name}.csv\"\n",
    "        df_pred.to_csv(path, index=False)\n",
    "        return path\n",
    "\n",
    "    Y_hat_knn_full = Y_full.copy()\n",
    "    Y_hat_enet_full = Y_full.copy()\n",
    "    Y_hat_knn_full[:, T_pref:T] = Y_pred_knn\n",
    "    Y_hat_enet_full[:, T_pref:T] = Y_pred_lr\n",
    "\n",
    "    full_paths = {\n",
    "        \"knn\": save_full_csv(Y_hat_knn_full, \"knn\"),\n",
    "        \"elasticnet\": save_full_csv(Y_hat_enet_full, \"elasticnet\"),\n",
    "    }\n",
    "\n",
    "    rows = []\n",
    "    for i, well in enumerate(wells_used):\n",
    "        for t in range(T):\n",
    "            segment = \"observed\" if t < T_pref else \"forecast\"\n",
    "            rows.append({\n",
    "                \"well_name\": well,\n",
    "                \"t\": t,\n",
    "                \"y_true\": float(Y_full[i, t]) if np.isfinite(Y_full[i, t]) else np.nan,\n",
    "                \"y_pred_knn\": float(Y_hat_knn_full[i, t]) if np.isfinite(Y_hat_knn_full[i, t]) else np.nan,\n",
    "                \"y_pred_elasticnet\": float(Y_hat_enet_full[i, t]) if np.isfinite(Y_hat_enet_full[i, t]) else np.nan,\n",
    "                \"segment\": segment,\n",
    "            })\n",
    "    long_df = pd.DataFrame(rows)\n",
    "    long_path = output_dir / \"pred_long.csv\"\n",
    "    long_df.to_csv(long_path, index=False)\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    def plot_full_example(idx: int, title_prefix: str, pred_full: np.ndarray) -> Path:\n",
    "        fig, ax = plt.subplots(figsize=(8, 4))\n",
    "        ax.plot(range(T), Y_full[idx], label=\"true\")\n",
    "        ax.plot(range(T), pred_full[idx], label=\"pred\")\n",
    "        ax.axvline(T_pref - 1, linestyle=\"--\")\n",
    "        ax.set_title(f\"{title_prefix} — {wells_used[idx]}\")\n",
    "        ax.set_xlabel(\"month index\")\n",
    "        ax.set_ylabel(\"oil rate (r_oil_s)\")\n",
    "        ax.legend()\n",
    "        path = output_dir / f\"{title_prefix.replace(' ', '_').lower()}_{idx}_full.png\"\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(path, dpi=140)\n",
    "        plt.close(fig)\n",
    "        return path\n",
    "\n",
    "    rng = np.random.default_rng(rng_seed)\n",
    "    valid_idx = np.where(np.isfinite(Y_pred_knn).all(axis=1))[0]\n",
    "    example_imgs: list[Path] = []\n",
    "    if valid_idx.size:\n",
    "        chosen = rng.choice(valid_idx, size=min(6, valid_idx.size), replace=False)\n",
    "        for idx in chosen:\n",
    "            example_imgs.append(plot_full_example(idx, \"knn_example\", Y_hat_knn_full))\n",
    "            example_imgs.append(plot_full_example(idx, \"enet_example\", Y_hat_enet_full))\n",
    "\n",
    "    html = f\"\"\"\n",
    "<html><head><meta charset='utf-8'><title>Forecast Report</title></head><body>\n",
    "<h2>Forecast evaluation (prefix {T_pref} → total {T})</h2>\n",
    "<p>Generated: {datetime.utcnow().isoformat()}Z</p>\n",
    "<table border='1' cellspacing='0' cellpadding='6'>\n",
    "<tr><th>Model</th><th>RMSE</th><th>sMAPE</th><th>N eval wells</th></tr>\n",
    "<tr><td>KNN</td><td>{metrics_knn['rmse']:.4f}</td><td>{metrics_knn['smape']:.4f}</td><td>{metrics_knn['n_eval']}</td></tr>\n",
    "<tr><td>ElasticNet</td><td>{metrics_lr['rmse']:.4f}</td><td>{metrics_lr['smape']:.4f}</td><td>{metrics_lr['n_eval']}</td></tr>\n",
    "</table>\n",
    "<h3>Files</h3>\n",
    "<ul>\n",
    "  <li>{metrics_path.name}</li>\n",
    "  <li>{suffix_paths['knn'].name}</li>\n",
    "  <li>{suffix_paths['elasticnet'].name}</li>\n",
    "  <li>{full_paths['knn'].name}</li>\n",
    "  <li>{full_paths['elasticnet'].name}</li>\n",
    "  <li>{long_path.name}</li>\n",
    "</ul>\n",
    "<h3>Full-series examples</h3>\n",
    "{''.join(f\"<img src='{img.name}' style='max-width:640px;display:block;margin-bottom:10px;'/>\" for img in example_imgs)}\n",
    "</body></html>\n",
    "\"\"\"\n",
    "    report_path = output_dir / \"forecast_report.html\"\n",
    "    report_path.write_text(html, encoding=\"utf-8\")\n",
    "\n",
    "    print(\"KNN   → RMSE={rmse:.4f}, sMAPE={smape:.4f}, N={n_eval}\".format(**metrics_knn))\n",
    "    print(\"ENet  → RMSE={rmse:.4f}, sMAPE={smape:.4f}, N={n_eval}\".format(**metrics_lr))\n",
    "    print(\"Артефакты сохранены в:\", output_dir)\n",
    "\n",
    "    return {\n",
    "        \"metrics\": metrics_df,\n",
    "        \"metrics_path\": metrics_path,\n",
    "        \"suffix_paths\": suffix_paths,\n",
    "        \"full_paths\": full_paths,\n",
    "        \"long_path\": long_path,\n",
    "        \"example_imgs\": example_imgs,\n",
    "        \"report_path\": report_path,\n",
    "        \"info\": {\"knn\": knn_info, \"enet\": lr_info},\n",
    "    }\n",
    "\n",
    "forecast_artifacts = None\n",
    "if RUN_FORECAST and preproc_out is not None:\n",
    "    forecast_artifacts = run_forecast_pipeline(\n",
    "        preproc_out,\n",
    "        T_pref=FORECAST_PREFIX,\n",
    "        output_dir=FORECAST_EXPORT_DIR,\n",
    "        rng_seed=RANDOM_SEED,\n",
    "    )\n",
    "pipeline_state[\"forecast\"] = forecast_artifacts\n"
   ],
   "id": "ad6780a26ce54537",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN   → RMSE=14.7542, sMAPE=0.5209, N=469\n",
      "ENet  → RMSE=29.1081, sMAPE=1.1633, N=469\n",
      "Артефакты сохранены в: reports/forecast_exports\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Сводка состояния пайплайна\n"
   ],
   "id": "de72e1864f823f2f"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T06:58:39.649829Z",
     "start_time": "2025-09-16T06:58:39.646945Z"
    }
   },
   "source": [
    "def summarize_state(state: Dict[str, Any]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for key, value in state.items():\n",
    "        rows.append({\n",
    "            \"step\": key,\n",
    "            \"available\": value is not None,\n",
    "            \"type\": type(value).__name__,\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "if pipeline_state:\n",
    "    display(summarize_state(pipeline_state))\n",
    "else:\n",
    "    print(\"pipeline_state пуст — проверьте выполнение предыдущих ячеек.\")\n"
   ],
   "id": "89686a88539e8c8e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            step  available       type\n",
       "0      dataframe       True  DataFrame\n",
       "1  preprocessing       True       dict\n",
       "2       manifold       True       dict\n",
       "3     clustering       True       dict\n",
       "4     pbm_report       True       dict\n",
       "5       forecast       True       dict"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>available</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataframe</td>\n",
       "      <td>True</td>\n",
       "      <td>DataFrame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>preprocessing</td>\n",
       "      <td>True</td>\n",
       "      <td>dict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>manifold</td>\n",
       "      <td>True</td>\n",
       "      <td>dict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clustering</td>\n",
       "      <td>True</td>\n",
       "      <td>dict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pbm_report</td>\n",
       "      <td>True</td>\n",
       "      <td>dict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>forecast</td>\n",
       "      <td>True</td>\n",
       "      <td>dict</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 24
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
