{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T08:42:03.867129Z",
     "start_time": "2025-09-14T08:42:03.865424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ],
   "id": "15a474bff337ef50",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T08:45:15.265669Z",
     "start_time": "2025-09-14T08:45:12.856126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# путь к папке\n",
    "folder = \"/Users/george/Documents/GitHub/manifold_learning/data\"\n",
    "\n",
    "# ищем все csv-файлы\n",
    "all_csv = glob.glob(os.path.join(folder, \"*.csv\"))\n",
    "\n",
    "# читаем и объединяем\n",
    "df = pd.concat((pd.read_csv(f) for f in all_csv), ignore_index=True)\n",
    "print(f\"Считано файлов: {len(all_csv)}\")"
   ],
   "id": "b79f397fa5e41d13",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Считано файлов: 4485\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T08:45:41.018381Z",
     "start_time": "2025-09-14T08:45:15.327878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = df.rename(columns={\"BBLS_OIL_COND\":\"oil\", \"MCF_GAS\": 'gas', \"BBLS_WTR\":\"water\", \"API_WellNo\":\"well_name\", \"RptDate\":\"date\"})\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "# важно, чтобы внутри каждой скважины ряды шли строго по времени\n",
    "df = df.sort_values(by=[\"well_name\", \"date\"]).reset_index(drop=True)\n",
    "\n",
    "df = df[(df['oil'] >= 0) & (df['gas'] >= 0) & (df['water'] >= 0)]\n",
    "\n",
    "# ресемплинг\n",
    "df = (\n",
    "    df.set_index(\"date\")\n",
    "      .groupby(\"well_name\")\n",
    "      .resample(\"M\").sum(numeric_only=True)\n",
    "      .reset_index()\n",
    ")"
   ],
   "id": "224375692889f4f7",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T08:47:41.926679Z",
     "start_time": "2025-09-14T08:47:26.825807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# стандартный метод через PCA и KMeans\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import silhouette_score\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# -------------------\n",
    "# ПАРАМЕТРЫ\n",
    "# -------------------\n",
    "WELL_COL = \"well_name\"\n",
    "DATE_COL = \"date\"\n",
    "OIL_COL  = \"oil\"\n",
    "GAS_COL  = \"gas\"\n",
    "WTR_COL  = \"water\"\n",
    "DAYS_COL = \"DAYS_PROD\"\n",
    "\n",
    "# Сигнал для сегментации: 'bopd' (барр/сут из BBLS_OIL_COND/DAYS_PROD),\n",
    "# 'bbl_mo' (месячные баррели), или 'mcfpd' (газ/сут) – выберите ниже:\n",
    "SIGNAL = \"bopd\"           # 'bopd' | 'bbl_mo' | 'mcfpd'\n",
    "\n",
    "# Старт профиля: первый месяц, когда ряд >= frac * (максимум внутри скважины)\n",
    "START_THRESHOLD_FRAC = 0.05\n",
    "MIN_CONSEC = 1\n",
    "\n",
    "# Горизонт (кол-во месяцев после старта). Если None → возьмём минимально доступный у всех скважин.\n",
    "HORIZON = 70  # поставьте 240, если у всех скважин 0..239\n",
    "\n",
    "# Поиск числа кластеров\n",
    "K_MIN, K_MAX = 1, 12\n",
    "ISF_CONTAMINATION = 0.03\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "OUT_DIR = Path(\"segm_long_output\"); OUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# -------------------\n",
    "# ВСПОМОГАТЕЛЬНОЕ\n",
    "# -------------------\n",
    "def monthly_signal_for_well(g: pd.DataFrame, signal_col: str) -> pd.Series:\n",
    "    # g — все строки одной скважины\n",
    "    g = g[[DATE_COL, OIL_COL, GAS_COL, WTR_COL, DAYS_COL] + [signal_col]].copy()\n",
    "    g[DATE_COL] = pd.to_datetime(g[DATE_COL])\n",
    "\n",
    "    # агрегируем на уровень календарного месяца\n",
    "    if signal_col == \"bopd\":\n",
    "        # средний суточный дебит нефти за месяц = (сумма баррелей) / (сумма дней)\n",
    "        oil_sum  = g.groupby(pd.Grouper(key=DATE_COL, freq=\"ME\"))[OIL_COL].sum(min_count=1)\n",
    "        days_sum = g.groupby(pd.Grouper(key=DATE_COL, freq=\"ME\"))[DAYS_COL].sum(min_count=1)\n",
    "        s = oil_sum / days_sum\n",
    "    elif signal_col == \"mcfpd\":\n",
    "        gas_sum  = g.groupby(pd.Grouper(key=DATE_COL, freq=\"ME\"))[GAS_COL].sum(min_count=1)\n",
    "        days_sum = g.groupby(pd.Grouper(key=DATE_COL, freq=\"ME\"))[DAYS_COL].sum(min_count=1)\n",
    "        s = gas_sum / days_sum\n",
    "    elif signal_col == \"bbl_mo\":\n",
    "        s = g.groupby(pd.Grouper(key=DATE_COL, freq=\"ME\"))[OIL_COL].sum(min_count=1)\n",
    "    else:\n",
    "        # на всякий случай: среднее по месяцу\n",
    "        s = g.groupby(pd.Grouper(key=DATE_COL, freq=\"ME\"))[signal_col].mean()\n",
    "\n",
    "    # нормализуем индекс к последнему дню месяца\n",
    "    s.index = s.index.to_period(\"M\").to_timestamp(\"M\")\n",
    "    return s.astype(float)\n",
    "\n",
    "\n",
    "def prep_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    # дата\n",
    "    df[DATE_COL] = pd.to_datetime(df[DATE_COL])\n",
    "    # чистка отрицательных и бессмысленных\n",
    "    for c in [OIL_COL, GAS_COL, WTR_COL, DAYS_COL]:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "            if c != DAYS_COL:\n",
    "                df.loc[df[c] < 0, c] = np.nan\n",
    "    df.loc[df[DAYS_COL] <= 0, DAYS_COL] = np.nan\n",
    "    # вычисляем суточные дебиты\n",
    "    df[\"bopd\"]   = df[OIL_COL] / df[DAYS_COL]\n",
    "    df[\"mcfpd\"]  = df[GAS_COL] / df[DAYS_COL]\n",
    "    df[\"bbl_mo\"] = df[OIL_COL]\n",
    "    # уберём нереальные пики (клипы по верхнему перцентилю по каждой скважине)\n",
    "    for col in [\"bopd\", \"mcfpd\", \"bbl_mo\"]:\n",
    "        if col not in df.columns: \n",
    "            continue\n",
    "        def _clip(g):\n",
    "            q99 = g[col].quantile(0.995)\n",
    "            g.loc[g[col] > q99, col] = np.nan\n",
    "            return g\n",
    "        df = df.groupby(WELL_COL, group_keys=False).apply(_clip)\n",
    "    return df\n",
    "\n",
    "def detect_start(series: pd.Series, thr_frac=START_THRESHOLD_FRAC, min_consec=MIN_CONSEC):\n",
    "    s = series.copy().astype(float).replace([np.inf, -np.inf], np.nan).interpolate(limit_direction=\"both\")\n",
    "    if s.dropna().empty: \n",
    "        return None\n",
    "    mmax = s.max()\n",
    "    if not np.isfinite(mmax) or mmax <= 0:\n",
    "        return None\n",
    "    thr = mmax * thr_frac\n",
    "    flags = s >= thr\n",
    "    run = 0\n",
    "    for i, f in enumerate(flags.values):\n",
    "        run = run + 1 if f else 0\n",
    "        if run >= min_consec:\n",
    "            return series.index[i - min_consec + 1]\n",
    "    return None\n",
    "\n",
    "def build_wide_matrix(df: pd.DataFrame, signal_col: str, horizon: int | None):\n",
    "    rows, wells, starts = [], [], []\n",
    "    # упорядочим месяцы строго по календарю\n",
    "    df = df.sort_values([WELL_COL, DATE_COL])\n",
    "    for w, g in df.groupby(WELL_COL):\n",
    "        s = monthly_signal_for_well(g, signal_col)     # <-- уникальный индекс по месяцам, без дублей\n",
    "    \n",
    "        if s.dropna().sum() == 0:\n",
    "            continue\n",
    "    \n",
    "        # старт\n",
    "        start_idx = detect_start(s, START_THRESHOLD_FRAC, MIN_CONSEC)\n",
    "        if start_idx is None:\n",
    "            continue\n",
    "    \n",
    "        g2 = s.loc[start_idx:].copy()\n",
    "        if g2.empty:\n",
    "            continue\n",
    "    \n",
    "        cal = pd.date_range(start_idx, g2.index.max(), freq=\"ME\")\n",
    "        g2 = g2.reindex(cal).interpolate(limit_direction=\"both\")\n",
    "    \n",
    "        g2.index = pd.Index(range(len(g2)), name=\"month_rel\")\n",
    "        rows.append(g2)\n",
    "        wells.append(w)\n",
    "        starts.append(start_idx)\n",
    "    if not rows:\n",
    "        raise RuntimeError(\"После выравнивания не осталось ни одной скважины.\")\n",
    "    # соберём в огромную таблицу (разные длины допустимы)\n",
    "    wide = pd.DataFrame(rows, index=wells).fillna(np.nan)\n",
    "    # выберем горизонт\n",
    "    if horizon is None:\n",
    "        horizon = int(wide.columns.max()) + 1\n",
    "    use_cols = [c for c in wide.columns if (isinstance(c, (int, np.integer)) and c < horizon)]\n",
    "    wide = wide.reindex(columns=use_cols)\n",
    "    # отфильтруем скважины, у которых не хватает горизонта\n",
    "    enough = wide.notna().sum(axis=1) >= len(use_cols)\n",
    "    wide = wide.loc[enough]\n",
    "    wells = list(wide.index)\n",
    "    starts = [s for w, s in zip(wells, starts) if w in wide.index]\n",
    "    return wide.to_numpy(dtype=float), wells, starts, len(use_cols)\n",
    "\n",
    "def zscore_rows(X: np.ndarray):\n",
    "    mu = np.nanmean(X, axis=1, keepdims=True)\n",
    "    sd = np.nanstd(X, axis=1, keepdims=True) + 1e-8\n",
    "    return (X - mu) / sd\n",
    "\n",
    "def pick_kmeans_auto(X, k_min=K_MIN, k_max=K_MAX):\n",
    "    best, best_sil = None, -1\n",
    "    sils = {}\n",
    "    for k in range(k_min, k_max+1):\n",
    "        km = KMeans(n_clusters=k, random_state=RANDOM_STATE, n_init=25).fit(X)\n",
    "        if len(set(km.labels_)) <= 1: \n",
    "            continue\n",
    "        s = silhouette_score(X, km.labels_)\n",
    "        sils[k] = float(s)\n",
    "        if s > best_sil:\n",
    "            best, best_sil = km, s\n",
    "    if best is None:\n",
    "        best = KMeans(n_clusters=3, random_state=RANDOM_STATE, n_init=25).fit(X)\n",
    "    return best, sils\n",
    "\n",
    "# -------------------\n",
    "# ОСНОВНОЙ ХОД\n",
    "# -------------------\n",
    "# 1) источник данных:\n",
    "# (а) если у вас уже есть df:\n",
    "# df = df\n",
    "# (б) либо загрузите:\n",
    "# df = pd.read_csv(\"your_file.csv\")  # или read_parquet/read_excel\n",
    "\n",
    "# >>> ЗДЕСЬ подставьте ваш df <<<\n",
    "# df = pd.read_csv(\"your_file.csv\")\n",
    "\n",
    "# ----- подготовка\n",
    "df = prep_df(df)\n",
    "\n",
    "# выбор сигнала\n",
    "signal_col = {\"bopd\":\"bopd\", \"bbl_mo\":\"bbl_mo\", \"mcfpd\":\"mcfpd\"}[SIGNAL]\n",
    "\n",
    "# 2) wide-матрица (скважины × месяцы от старта)\n",
    "X_orig, wells, start_dates, horizon_used = build_wide_matrix(df, signal_col, HORIZON)\n",
    "\n",
    "print(f\"Скважин после фильтра: {len(wells)}; горизонт: {horizon_used} мес; сигнал: {signal_col}\")\n",
    "\n",
    "# 3) нормировка по форме\n",
    "X = zscore_rows(X_orig)\n",
    "\n",
    "# 4) кластеризация + аутлаеры\n",
    "kmeans, sils = pick_kmeans_auto(X, K_MIN, K_MAX)\n",
    "labels = kmeans.predict(X)\n",
    "isf = IsolationForest(n_estimators=300, contamination=ISF_CONTAMINATION,\n",
    "                      random_state=RANDOM_STATE).fit(X)\n",
    "outliers = (isf.predict(X) == -1)\n",
    "\n",
    "print(\"Подбор K по силуэту:\", sils)\n",
    "print(\"Выбрано кластеров:\", kmeans.n_clusters)\n",
    "\n",
    "# 5) PCA-визуализация + доли объяснённой дисперсии\n",
    "pca = PCA(n_components=2, random_state=RANDOM_STATE).fit(X)\n",
    "Z = pca.transform(X)\n",
    "evr = pca.explained_variance_ratio_\n",
    "print(f\"Explained variance: PC1={evr[0]*100:.1f}%, PC2={evr[1]*100:.1f}%\")\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "for c in sorted(set(labels)):\n",
    "    m = (labels==c) & (~outliers)\n",
    "    plt.scatter(Z[m,0], Z[m,1], s=25, alpha=0.8, label=f\"Кластер {c}\")\n",
    "plt.scatter(Z[outliers,0], Z[outliers,1], s=60, marker=\"x\", label=\"Аутлаеры\", c=\"k\")\n",
    "plt.title(f\"PCA: {SIGNAL} | N={len(wells)} | K={kmeans.n_clusters}\\n\"\n",
    "          f\"PC1={evr[0]*100:.1f}%  PC2={evr[1]*100:.1f}%\")\n",
    "plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\"); plt.legend()\n",
    "plt.tight_layout(); plt.savefig(OUT_DIR/\"pca_scatter.png\", dpi=160); plt.close()\n",
    "\n",
    "# 6) средние кривые кластеров (в исходных единицах сигнала)\n",
    "t = np.arange(horizon_used)\n",
    "plt.figure(figsize=(10,7))\n",
    "for c in sorted(set(labels)):\n",
    "    Xc = X_orig[labels==c]\n",
    "    if Xc.size==0: continue\n",
    "    mean = np.nanmean(Xc, axis=0)\n",
    "    p10  = np.nanpercentile(Xc, 10, axis=0)\n",
    "    p90  = np.nanpercentile(Xc, 90, axis=0)\n",
    "    plt.plot(t, mean, label=f\"Кластер {c}\")\n",
    "    plt.fill_between(t, p10, p90, alpha=0.15)\n",
    "plt.title(f\"Средние профили (ед.: {SIGNAL})\")\n",
    "plt.xlabel(\"Месяц от старта\"); plt.ylabel(SIGNAL)\n",
    "plt.tight_layout(); plt.legend()\n",
    "plt.savefig(OUT_DIR/\"cluster_means.png\", dpi=160); plt.close()\n",
    "\n",
    "# 7) выгрузки\n",
    "pd.DataFrame({\n",
    "    \"well\": wells,\n",
    "    \"cluster\": labels,\n",
    "    \"is_outlier\": outliers,\n",
    "    \"start_date\": start_dates\n",
    "}).to_csv(OUT_DIR/\"clustered_wells.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"Готово. Смотрите папку:\", OUT_DIR.resolve())\n"
   ],
   "id": "a9a7bfcf53dc6abf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Скважин после фильтра: 2032; горизонт: 70 мес; сигнал: bopd\n",
      "Подбор K по силуэту: {2: 0.2476759902188048, 3: 0.15909158887806013, 4: 0.10343935487439704, 5: 0.09325364776183989, 6: 0.09466025699487236, 7: 0.0840743098180394, 8: 0.08379450470539342, 9: 0.06541837274385999, 10: 0.079764981268202, 11: 0.07614426063525631, 12: 0.07484974303088747}\n",
      "Выбрано кластеров: 2\n",
      "Explained variance: PC1=26.5%, PC2=13.4%\n",
      "Готово. Смотрите папку: /Users/george/Documents/GitHub/manifold_learning/notebooks/segm_long_output\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1dd495de0721ecd1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
